"""
Usage Metrics Aggregator - Scheduled service for CloudWatch ‚Üí DynamoDB

This service runs hourly via EventBridge to:
1. Fetch CloudWatch metrics for all Lambda functions
2. Calculate incremental usage (requests + GB-Seconds)
3. Store aggregated data in DynamoDB

Industry-standard approach ensures usage persists even after function deletion.
"""
import os
from datetime import datetime, timedelta
from typing import Dict, List

import boto3
from boto3.dynamodb.conditions import Key

from api.db.dynamodb import (
    get_or_create_table,
    get_current_period,
    increment_org_usage,
)
from deployer import extract_project_name
from deployer.aws.lambda_service import get_lambda_function_name


# CloudWatch client
cloudwatch = boto3.client("cloudwatch")


def get_cloudwatch_metric_sum(
    function_name: str,
    metric_name: str,
    start_time: datetime,
    end_time: datetime,
) -> float:
    """
    Get sum of a CloudWatch metric for a Lambda function over a time period.
    
    Args:
        function_name: Lambda function name
        metric_name: CloudWatch metric name (e.g., "Invocations", "Duration")
        start_time: Start of time range
        end_time: End of time range
        
    Returns:
        Sum of metric values, or 0.0 if no data
    """
    try:
        response = cloudwatch.get_metric_statistics(
            Namespace="AWS/Lambda",
            MetricName=metric_name,
            Dimensions=[
                {
                    "Name": "FunctionName",
                    "Value": function_name,
                }
            ],
            StartTime=start_time,
            EndTime=end_time,
            Period=3600,  # 1 hour granularity
            Statistics=["Sum"],
        )
        
        datapoints = response.get("Datapoints", [])
        if not datapoints:
            return 0.0
        
        # Sum all datapoint values
        total = sum(dp.get("Sum", 0.0) for dp in datapoints)
        return float(total)
        
    except Exception as e:
        print(f"Error fetching {metric_name} for {function_name}: {e}")
        return 0.0


def get_hourly_invocations(function_name: str) -> int:
    """Get number of invocations in the last hour."""
    end_time = datetime.utcnow()
    start_time = end_time - timedelta(hours=1)
    
    invocations = get_cloudwatch_metric_sum(
        function_name,
        "Invocations",
        start_time,
        end_time,
    )
    return int(invocations)


def get_hourly_gb_seconds(function_name: str, memory_mb: int) -> float:
    """
    Calculate GB-Seconds for a function in the last hour.
    
    GB-Seconds = (Duration_ms / 1000) * (Memory_MB / 1024) / 1000
    
    Note: CloudWatch Duration is in milliseconds, Memory is in MB.
    We convert to GB-Seconds for billing calculations.
    """
    end_time = datetime.utcnow()
    start_time = end_time - timedelta(hours=1)
    
    # Get total duration in milliseconds
    total_duration_ms = get_cloudwatch_metric_sum(
        function_name,
        "Duration",
        start_time,
        end_time,
    )
    
    if total_duration_ms == 0:
        return 0.0
    
    # Convert to GB-Seconds
    # Duration: ms ‚Üí seconds (/ 1000)
    # Memory: MB ‚Üí GB (/ 1024)
    # Result in GB-Seconds
    duration_seconds = total_duration_ms / 1000.0
    memory_gb = memory_mb / 1024.0
    gb_seconds = duration_seconds * memory_gb
    
    return gb_seconds


def get_all_projects() -> List[Dict]:
    """Get all projects from DynamoDB."""
    table = get_or_create_table()
    
    # Scan for all project items
    # In production with many users, use pagination
    response = table.scan(
        FilterExpression="begins_with(SK, :sk_prefix)",
        ExpressionAttributeValues={
            ":sk_prefix": "PROJECT#",
        },
    )
    
    return response.get("Items", [])


def aggregate_usage_metrics():
    """
    Main aggregation function - called by EventBridge hourly.
    
    Fetches CloudWatch metrics for all projects and stores in DynamoDB.
    """
    print(f"üîÑ Starting usage metrics aggregation at {datetime.utcnow().isoformat()}")
    
    # Get all projects
    projects = get_all_projects()
    print(f"üìä Found {len(projects)} projects to aggregate")
    
    if not projects:
        print("‚úÖ No projects to aggregate")
        return
    
    # Group projects by organization_id (orgs are the billing entity)
    orgs_projects: Dict[str, List[Dict]] = {}
    for project in projects:
        org_id = project.get("organization_id")
        if not org_id:
            continue
        if org_id not in orgs_projects:
            orgs_projects[org_id] = []
        orgs_projects[org_id].append(project)
    
    print(f"üè¢ Aggregating for {len(orgs_projects)} organizations")
    
    # Get current billing period
    period = get_current_period()
    
    # Aggregate metrics for each organization
    total_requests = 0
    total_gb_seconds = 0.0
    
    for org_id, org_projects in orgs_projects.items():
        org_requests = 0
        org_gb_seconds = 0.0
        
        for project in org_projects:
            # Skip if project is not LIVE
            if project.get("status") != "LIVE":
                continue
            
            # Get function name - prefer stored function_name, fallback to deriving from github_url
            # for backwards compatibility with projects that don't have function_name stored
            stored_function_name = project.get("function_name")
            if stored_function_name:
                # Apply shorlabs- prefix to get full Lambda function name
                function_name = get_lambda_function_name(stored_function_name)
            else:
                # Fallback: derive from github_url and apply prefix
                project_name = extract_project_name(project.get("github_url", ""))
                if not project_name:
                    continue
                function_name = get_lambda_function_name(project_name)
            
            memory_mb = int(project.get("memory", 1024))
            
            # Fetch metrics from CloudWatch
            try:
                invocations = get_hourly_invocations(function_name)
                gb_seconds = get_hourly_gb_seconds(function_name, memory_mb)
                
                if invocations > 0 or gb_seconds > 0:
                    print(f"  üìà {function_name}: {invocations} invocations, {gb_seconds:.2f} GB-s")
                    org_requests += invocations
                    org_gb_seconds += gb_seconds
                    
            except Exception as e:
                print(f"  ‚ùå Error aggregating {function_name}: {e}")
                continue
        
        # Update organization's usage in DynamoDB if there's any activity
        if org_requests > 0 or org_gb_seconds > 0:
            try:
                increment_org_usage(
                    org_id=org_id,
                    period=period,
                    requests=org_requests,
                    gb_seconds=org_gb_seconds,
                )
                print(f"‚úÖ Updated usage for org {org_id}: +{org_requests} requests, +{org_gb_seconds:.2f} GB-s")
                total_requests += org_requests
                total_gb_seconds += org_gb_seconds
            except Exception as e:
                print(f"‚ùå Failed to update usage for org {org_id}: {e}")
    
    print(f"üéâ Aggregation complete!")
    print(f"   Total: {total_requests} requests, {total_gb_seconds:.2f} GB-Seconds")
    print(f"   Period: {period}")
